# ðŸŽ¯ PROMPT ARQUITETONICAMENTE COMPLETO
## Agent AI Senior para Orquestrar Tool Registry do CRM Refrimix

Cole este prompt **EXATAMENTE** no Agent Manager do AntiGravity ou no Cursor.ai:

---

```
You are a SENIOR AI ARCHITECT specializing in Agentic AI Systems and Tool Orchestration.

PROJECT: CRM Refrimix Tecnologia - CÃ©rebro Refrimix (Agentic Chatbot with Tool Control)

YOUR MISSION:
1. Analyze the current codebase architecture
2. Understand the existing Tool Registry and AIManager
3. Design an ENTERPRISE-GRADE agentic system
4. Implement proper Tool Registry patterns
5. Create intelligent routing and delegation logic
6. Ensure multi-provider AI support (OpenAI, Ollama, Gemini, Anthropic, Perplexity)

---

## PHASE 1: CODEBASE ANALYSIS & ARCHITECTURE REVIEW (30 mins)

**STEP 1A: Analyze Current Implementation**

```bash
# 1. Find and list the current chatbot files
find src -type f \( -name "*[Cc]hat*" -o -name "*[Cc]erebro*" -o -name "*[Aa]gentic*" \) | sort

# 2. Find AIManager and ToolRegistry
find src -type f -name "*[Aa]I*" -o -name "*[Tt]ool*" -o -name "*[Rr]egistry*" | sort

# 3. Check current hooks structure
find src/hooks -type f | sort

# 4. Review pages structure
find src/pages -type f | sort

# 5. Check existing Tool definitions
grep -r "tools:\|Tool\|function.*tool\|export.*tool" src --include="*.ts" --include="*.tsx" | head -50

# 6. Check current API integrations
grep -r "fetch\|axios\|supabase\|api" src --include="*.ts" --include="*.tsx" | grep -i "leads\|inventory\|tasks\|finance" | head -20
```

Output these results and analyze:
- [ ] Current Tool Registry structure
- [ ] How AIManager orchestrates tools
- [ ] How Supabase queries are called
- [ ] Current authentication and data access patterns
- [ ] Missing or incomplete tool implementations

**STEP 1B: Document Current CRM Functions**

For each module (Leads, Inventory, Tasks, Finance), document:

```bash
# Example for Leads
grep -A 20 "export.*Leads\|function.*Leads\|const.*Leads" src/pages/Leads.tsx

# Check hooks
grep -A 20 "export.*useLeads\|function.*useLeads" src/hooks/*.ts
```

Create a structured analysis:
```
# CRM MODULES INVENTORY

## 1. Leads Management
- Location: src/pages/Leads.tsx
- Hook: src/hooks/useLeads.ts
- Supabase table: leads
- CRUD operations: [list them]
- Required tool calls: [create_lead, update_lead, delete_lead, fetch_leads]

## 2. Inventory Management
- Location: src/pages/Inventory.tsx
- Hook: src/hooks/useInventory.ts
- Supabase table: inventory
- CRUD operations: [list them]
- Required tool calls: [list them]

## 3. Tasks Management
- Location: src/pages/Tasks.tsx
- Hook: src/hooks/useTasks.ts
- Supabase table: tasks
- CRUD operations: [list them]
- Required tool calls: [list them]

## 4. Finance Management
- Location: src/pages/Finance.tsx
- Hook: src/hooks/useTransactions.ts
- Supabase table: transactions
- CRUD operations: [list them]
- Required tool calls: [list them]
```

**STEP 1C: Identify Current Gaps**

Check for missing implementations:
```bash
# Is ToolRegistry fully defined?
find src -name "*ToolRegistry*" -exec cat {} \;

# What tools are currently registered?
grep -r "tools\s*=\|tool_registry\|ToolRegistry" src --include="*.ts" --include="*.tsx"

# Are there error handling patterns?
grep -r "try\|catch\|error\|Error" src/hooks --include="*.ts" | wc -l

# Check for existing types
find src -name "*.types.ts" -o -name "*.d.ts" | xargs ls -la
```

Document:
- [ ] Which tools are missing from registry
- [ ] Which CRUD operations need tool wrappers
- [ ] Error handling gaps
- [ ] Type definition gaps
- [ ] API integration gaps

---

## PHASE 2: ENTERPRISE AGENTIC ARCHITECTURE DESIGN (60 mins)

### PART 2A: Tool Registry Pattern (ReAct-Based)

Based on research findings, implement this PROVEN pattern:

```typescript
// src/lib/tool-registry/types.ts
// COMPREHENSIVE TOOL DEFINITIONS

export interface ToolSchema {
  name: string;
  description: string;
  parameters: {
    type: "object";
    properties: Record<string, any>;
    required: string[];
  };
}

export interface ToolResult {
  success: boolean;
  data?: any;
  error?: string;
  executedAt: string;
}

export interface ToolContext {
  userId: string;
  userRole: "admin" | "user" | "viewer";
  timestamp: number;
  metadata?: Record<string, any>;
}

export interface ToolExecutionLog {
  toolName: string;
  status: "pending" | "success" | "failed";
  result: ToolResult;
  executedAt: string;
  duration: number; // in ms
}
```

### PART 2B: Tool Categories (Based on CRM Modules)

Design 4 main tool categories matching your CRM:

```typescript
// CATEGORY 1: NAVIGATION TOOLS
// Purpose: Agent tells user to navigate to a page
// Tools:
//   - navigate_to_page(page: "leads" | "inventory" | "tasks" | "finance" | "dashboard")
//   - open_settings()
//   - close_chatbot()

// CATEGORY 2: LEADS MANAGEMENT TOOLS
// Purpose: Full CRUD operations on leads
// Tools:
//   - create_lead(name, email, phone, status, company)
//   - fetch_leads(filters?: {status?, company?, name?})
//   - update_lead(id, fields)
//   - delete_lead(id)
//   - search_lead_by_name(query)
//   - change_lead_status(id, status)

// CATEGORY 3: INVENTORY MANAGEMENT TOOLS
// Purpose: Track inventory items
// Tools:
//   - create_inventory_item(name, sku, quantity, price, category)
//   - fetch_inventory(filters?: {category?, below_quantity?})
//   - update_inventory(id, fields)
//   - delete_inventory(id)
//   - adjust_quantity(id, change)
//   - check_stock_level(id)

// CATEGORY 4: TASKS MANAGEMENT TOOLS
// Purpose: Task assignment and tracking
// Tools:
//   - create_task(title, description, assigned_to, due_date, priority)
//   - fetch_tasks(filters?: {status?, priority?, assigned_to?})
//   - update_task(id, fields)
//   - mark_task_complete(id)
//   - delete_task(id)
//   - get_my_tasks()

// CATEGORY 5: FINANCE MANAGEMENT TOOLS
// Purpose: Expense and income tracking
// Tools:
//   - add_expense(amount, description, category, entity_type, entity_id)
//   - add_income(amount, description, source, entity_type, entity_id)
//   - fetch_transactions(filters?: {date_range?, category?, entity_type?})
//   - get_total_revenue(period)
//   - get_total_expenses(period)
//   - delete_transaction(id)
//   - filter_by_entity(entity_type, entity_id)

// CATEGORY 6: REPORTING & ANALYTICS TOOLS
// Purpose: Generate insights and reports
// Tools:
//   - get_dashboard_metrics()
//   - get_revenue_by_month(months?: number)
//   - get_conversion_rate()
//   - get_inventory_status()
//   - get_task_completion_rate()
```

### PART 2C: Tool Execution Flow (LangGraph-inspired)

Design the agent decision-making flow:

```
User Input
    â†“
[LLM Router Node]
    â†“
â”œâ”€â†’ [Classify Intent]
â”‚       â†“
â”‚    Intent Type?
â”‚    â”œâ”€ "NAVIGATE" â†’ [Nav Tool Node]
â”‚    â”œâ”€ "CREATE" â†’ [Create Tool Node]
â”‚    â”œâ”€ "QUERY" â†’ [Query Tool Node]
â”‚    â”œâ”€ "UPDATE" â†’ [Update Tool Node]
â”‚    â”œâ”€ "DELETE" â†’ [Delete Tool Node]
â”‚    â”œâ”€ "REPORT" â†’ [Analytics Tool Node]
â”‚    â””â”€ "CHAT" â†’ [Response Node]
â”‚       â†“
â”œâ”€â†’ [Tool Execution Node]
â”‚       â†“
â”‚    â”œâ”€ Validate parameters
â”‚    â”œâ”€ Check permissions
â”‚    â”œâ”€ Execute Supabase query
â”‚    â”œâ”€ Log execution
â”‚    â””â”€ Return result
â”‚       â†“
â”œâ”€â†’ [Result Formatting Node]
â”‚       â†“
â”‚    â”œâ”€ If tool succeeded â†’ Format for user
â”‚    â”œâ”€ If tool failed â†’ Explain error
â”‚    â””â”€ Add context and suggestions
â”‚       â†“
â””â”€â†’ [Response Generation Node]
        â†“
    [Send to User]
```

### PART 2D: Error Recovery & Fallback Strategy

```typescript
// TIER 1: Graceful Degradation
// If specific tool fails â†’ Offer alternative paths
// Example: If "update_lead" fails â†’ Suggest "delete and recreate"

// TIER 2: Data Validation
// Before tool execution:
// - Check parameter types
// - Validate Supabase connection
// - Check user permissions
// - Verify data constraints

// TIER 3: Detailed Error Messages
// Return structured error:
// {
//   error: "INVALID_LEAD_ID",
//   message: "Lead with ID '123' not found",
//   suggestions: ["Search by name instead", "Create new lead"]
// }

// TIER 4: Execution Logging
// Log every tool call for debugging:
// - User ID
// - Tool name
// - Parameters (sanitized)
// - Status (pending â†’ success/failed)
// - Duration
// - Error details (if failed)
```

---

## PHASE 3: IMPLEMENTATION SPECIFICATION (90 mins)

### PART 3A: File Structure to Create

```
src/
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ agent/
â”‚       â”œâ”€â”€ types.ts                 # Core types
â”‚       â”œâ”€â”€ tool-registry.ts         # Tool definitions
â”‚       â”œâ”€â”€ tool-executor.ts         # Execute tools safely
â”‚       â”œâ”€â”€ ai-router.ts             # Route to correct AI provider
â”‚       â”œâ”€â”€ permission-checker.ts    # Validate user can use tool
â”‚       â”œâ”€â”€ error-handler.ts         # Standardized error handling
â”‚       â””â”€â”€ logger.ts                # Tool execution logging
â”‚
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useAgentChat.ts              # Chat state management
â”‚   â”œâ”€â”€ useToolExecution.ts          # Execute tools
â”‚   â””â”€â”€ useAIProvider.ts             # Switch between AI providers
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatInterface.tsx            # Chat UI
â”‚   â”œâ”€â”€ ToolStatusIndicator.tsx      # Show tool execution status
â”‚   â””â”€â”€ AgentSettings.tsx            # Provider/tool configuration
â”‚
â””â”€â”€ services/
    â””â”€â”€ agent/
        â”œâ”€â”€ leads-tools.ts           # Lead-specific tool implementations
        â”œâ”€â”€ inventory-tools.ts       # Inventory-specific tool implementations
        â”œâ”€â”€ tasks-tools.ts           # Task-specific tool implementations
        â””â”€â”€ finance-tools.ts         # Finance-specific tool implementations
```

### PART 3B: Core Implementation Requirements

**1. Tool Registry (tool-registry.ts)**
- [ ] Export all 25+ tools with full schemas
- [ ] Include examples for each tool
- [ ] Add parameter validation
- [ ] Include tool categories
- [ ] Version each tool
- [ ] Add deprecation warnings if needed

**2. Tool Executor (tool-executor.ts)**
- [ ] Validate input parameters
- [ ] Check user permissions
- [ ] Execute Supabase queries
- [ ] Handle errors gracefully
- [ ] Log execution
- [ ] Return structured results
- [ ] Support timeouts (30s max)

**3. AI Router (ai-router.ts)**
- [ ] Support 5 providers (OpenAI, Ollama, Gemini, Anthropic, Perplexity)
- [ ] Route based on user preference
- [ ] Fall back if provider unavailable
- [ ] Respect rate limits
- [ ] Cache tool schemas in memory
- [ ] Track token usage per provider

**4. Tool Bindings (leads-tools.ts, etc)**
- [ ] Bind each tool to actual Supabase queries
- [ ] Use existing hooks (useLeads, useInventory, etc)
- [ ] Add caching where appropriate
- [ ] Handle pagination for large queries
- [ ] Return paginated results properly

**5. Error Handling (error-handler.ts)**
- [ ] Custom error types (ToolNotFoundError, PermissionError, etc)
- [ ] User-friendly error messages
- [ ] Suggestion generation
- [ ] Error categorization
- [ ] Retry logic for transient failures

**6. Logging (logger.ts)**
- [ ] Log all tool executions
- [ ] Include timing information
- [ ] Store in localStorage + optional backend
- [ ] Support log export for debugging
- [ ] Privacy-compliant (no sensitive data)

### PART 3C: Integration Points

Identify and document all integration points:

```bash
# 1. With existing hooks
- Integrate useLeads.ts with lead-tools.ts
- Integrate useInventory.ts with inventory-tools.ts
- Integrate useTasks.ts with tasks-tools.ts
- Integrate useTransactions.ts with finance-tools.ts

# 2. With Supabase
- Use existing queries
- Add tool-specific queries
- Implement caching layer
- Add row-level security checks

# 3. With UI/Navigation
- Use existing router
- Update URL when navigating via tools
- Preserve scroll position
- Clear filters when navigating

# 4. With Auth
- Use existing auth context
- Check permissions for each tool
- Log audit trail
- Respect role-based access
```

### PART 3D: Data Flow Examples

**Example 1: Create Lead via Agent**
```
User: "Create a new lead for JoÃ£o da Silva from Daikin"
  â†“
[LLM] Classify as "CREATE_LEAD"
  â†“
[Tool Executor] create_lead(
  name="JoÃ£o da Silva",
  company="Daikin",
  email=null,
  phone=null,
  status="novo"
)
  â†“
[Permission Check] âœ“ User has permission
  â†“
[Supabase Query] INSERT into leads
  â†“
[Result Formatter] "Lead created successfully. ID: 12345"
  â†“
[Chat Response] "Criei o lead para JoÃ£o da Silva (Daikin). Quer que eu navegue para ver os detalhes?"
```

**Example 2: Query Finance Data**
```
User: "Quanto ganhei no financeiro esse mÃªs?"
  â†“
[LLM] Classify as "QUERY_REVENUE"
  â†“
[Tool Executor] get_total_revenue(period="current_month")
  â†“
[Supabase Query] SUM(amount) WHERE type='income' AND date >= first_day_of_month
  â†“
[Result Formatter] Converts to readable format
  â†“
[Chat Response] "VocÃª ganhou R$ 25,000 esse mÃªs. Quer ver detalhes por categoria?"
```

**Example 3: Error Recovery**
```
User: "Delete lead 999"
  â†“
[Tool Executor] delete_lead(id="999")
  â†“
[Supabase Query] DELETE FROM leads WHERE id = 999
  â†“
[Error] Lead not found!
  â†“
[Error Handler] Structured error response
  â†“
[Chat Response] "Lead 999 nÃ£o encontrado. Quer que eu procure por nome? Qual Ã© o nome do lead?"
```

---

## PHASE 4: VALIDATION & TESTING (45 mins)

### PART 4A: Unit Tests Required

For each tool, create tests:

```bash
# Test successful execution
âœ“ Tool executes with valid parameters
âœ“ Tool returns correct data format
âœ“ Tool respects pagination

# Test error cases
âœ“ Tool rejects invalid parameters
âœ“ Tool handles Supabase errors
âœ“ Tool respects permissions
âœ“ Tool logs execution

# Test edge cases
âœ“ Tool handles empty results
âœ“ Tool handles very large results
âœ“ Tool handles special characters
âœ“ Tool handles concurrent calls
```

### PART 4B: Integration Tests

```bash
# Test tool + AI flow
âœ“ User message â†’ Tool selection â†’ Tool execution â†’ Response

# Test multi-tool flows
âœ“ User: "Create lead and add task"
âœ“ User: "Show inventory below 10 and order new"

# Test error recovery
âœ“ Tool fails, agent offers alternatives
âœ“ User corrects input, tool succeeds

# Test provider switching
âœ“ Switch from OpenAI to Ollama
âœ“ Switch from Gemini to Anthropic
```

### PART 4C: Performance Benchmarks

```bash
# Measure and optimize:
- Time to first response: < 2s
- Tool execution time: < 5s per tool
- Memory usage: < 50MB for chat history
- Token usage: Log per request

# Define SLOs:
- 99% of requests < 3s
- 99.5% availability
- 0 data loss
- < 0.1% error rate
```

---

## PHASE 5: DELIVERABLES

When implementation is complete, generate these ARTIFACTS:

### ARTIFACT 1: Architecture Document
```
# CRM Refrimix - Agentic Architecture

## 1. System Overview
[Diagram of agent flow]

## 2. Tool Registry
[Complete list of all tools with schemas]

## 3. Data Flow
[Examples of key workflows]

## 4. Error Handling
[Error categorization and recovery]

## 5. Security
[Permissions, audit trail, data privacy]

## 6. Performance
[Benchmarks, optimization notes]

## 7. Deployment
[Step-by-step deployment guide]
```

### ARTIFACT 2: Implementation Checklist
```
Code Structure:
  âœ“ src/lib/agent/ created
  âœ“ All tool files implemented
  âœ“ Types defined
  âœ“ Exports correct

Tool Registry:
  âœ“ All 25+ tools defined
  âœ“ Schemas complete
  âœ“ Examples included
  âœ“ Validation working

Integration:
  âœ“ Hooks integrated
  âœ“ Supabase queries working
  âœ“ Navigation working
  âœ“ Auth checks working

Testing:
  âœ“ All unit tests passing
  âœ“ Integration tests passing
  âœ“ No console errors
  âœ“ Performance OK

Documentation:
  âœ“ API docs complete
  âœ“ Tool schemas documented
  âœ“ Examples provided
  âœ“ README updated
```

### ARTIFACT 3: Code Examples
```
[Complete working examples for:]
- Creating a new tool
- Executing a tool
- Handling errors
- Switching AI providers
- Logging tool execution
```

---

## SUCCESS CRITERIA âœ…

Task is COMPLETE when:

âœ… All 25+ tools properly defined in ToolRegistry
âœ… Tool executor works with real Supabase queries
âœ… Multi-provider AI routing implemented
âœ… Error handling and recovery working
âœ… Logging and audit trail in place
âœ… Chat interface responsive
âœ… Settings panel allows provider selection
âœ… Zero console errors
âœ… Agent successfully executes commands:
   - "VÃ¡ para o financeiro" â†’ Navigates
   - "Crie um lead para JoÃ£o" â†’ Creates lead
   - "Mostra meus leads" â†’ Lists leads
   - "Quanto ganhei essa semana?" â†’ Shows revenue
âœ… All unit tests passing
âœ… All integration tests passing
âœ… Architecture document complete
âœ… Code is production-ready

---

## EXECUTION GUIDELINES

**DO THIS FIRST:**
1. Run Phase 1 analysis scripts
2. Document current state
3. Identify gaps
4. Report findings

**THEN:**
1. Design tool registry
2. Create file structure
3. Implement tools incrementally
4. Test each tool
5. Integrate with UI
6. Final validation

**CONSTRAINTS:**
- No breaking changes to existing UI
- Keep using existing hooks (useLeads, etc)
- Maintain Supabase RLS policies
- Preserve authentication flow
- Support all 5 AI providers

**COMMUNICATION:**
- Report findings after Phase 1
- Share architecture after Phase 2
- Show implementation progress every 20 mins
- Generate artifacts per phase

---

## SENIOR DEVELOPER NOTES

This implementation follows:
âœ“ ReAct Agent Pattern (O'Neill et al. 2022)
âœ“ Tool Use Best Practices (OpenAI, Anthropic)
âœ“ LangGraph State Management
âœ“ SQL Agent Error Recovery
âœ“ Enterprise Tool Registry Patterns
âœ“ CRM Integration Best Practices
âœ“ Token-Efficient Prompting
âœ“ Multi-Provider Routing

Key principles:
- **Stateful**: Maintain conversation context
- **Safe**: Validate before execution
- **Transparent**: Log everything
- **Resilient**: Graceful error handling
- **Efficient**: Cache, reuse, optimize
- **Auditable**: Full execution trail
- **Scalable**: Support growing tool count

---

ðŸŽ¯ START PHASE 1 NOW AND REPORT FINDINGS!
```

---

## ðŸ“‹ COMO USAR ESTE PROMPT

### **OpÃ§Ã£o A: No AntiGravity Agent Manager**
1. Copie todo o prompt (bloco com ```)
2. Abra AntiGravity
3. Cole no campo "Task/Prompt"
4. Clique "Run Agent"
5. Aguarde 60-120 minutos pelas artifacts

### **OpÃ§Ã£o B: No Cursor.ai / Claude**
1. Copie o prompt
2. Abra Cursor.ai ou claude.com
3. Cole em uma nova conversa
4. Cole tambÃ©m o link do repo
5. Deixe processar

### **OpÃ§Ã£o C: Localmente no Terminal (Mais rÃ¡pido)**
```bash
# Se quiser fazer TUDO vocÃª mesmo:

# 1. AnÃ¡lise do repositÃ³rio
find src -type f \( -name "*[Cc]hat*" -o -name "*[Aa]gent*" \) | head -20
find src/hooks -type f | sort

# 2. Entender estrutura
head -50 src/pages/Leads.tsx
head -50 src/hooks/useLeads.ts

# 3. Iniciar implementaÃ§Ã£o
mkdir -p src/lib/agent
# ... criar arquivos conforme o prompt

# 4. Testar incrementalmente
npm run dev
npm test
```

---

## ðŸš€ DIFERENCIAL DESTA ABORDAGEM

**Por que este prompt Ã© melhor que os anteriores:**

1. **Arquiteturalmente Correto**
   - Baseado em padrÃµes comprovados (ReAct, LangGraph)
   - Segue best practices da industria
   - EscalÃ¡vel para 50+ tools no futuro

2. **Contextualmente EspecÃ­fico**
   - Analisa PRIMEIRO seu cÃ³digo
   - Entende sua estrutura
   - Se integra com hooks existentes

3. **HolÃ­stica**
   - NÃ£o Ã© sÃ³ front-end
   - NÃ£o Ã© sÃ³ backend
   - Ã‰ SISTEMA COMPLETO

4. **Orientada a Resultados**
   - Define exatamente o que precisa ser feito
   - Tem checkpoints claros
   - Tem sucesso definido

5. **Documentada**
   - Explica PORQUÃŠ de cada decisÃ£o
   - Mostra exemplos reais
   - Facilita manutenÃ§Ã£o futura

6. **Enterprise-Ready**
   - Error recovery
   - Logging/Audit
   - Permissions/Security
   - Multi-provider support
   - Performance monitoring

---

## ðŸ“Š TIMELINE ESPERADA

- **Phase 1** (30 min): AnÃ¡lise e entendimento
- **Phase 2** (60 min): Design e arquitetura
- **Phase 3** (90 min): ImplementaÃ§Ã£o
- **Phase 4** (45 min): Testes e validaÃ§Ã£o
- **Phase 5** (30 min): DocumentaÃ§Ã£o e artifacts

**Total: ~255 minutos (4-4.5 horas)**

Se rodar com agent (AntiGravity): 3-4 horas
Se implementar manualmente: 6-8 horas

---

ðŸŽ¯ **Este prompt transforma seu chatbot em um ENTERPRISE AGENT SYSTEM!**

Pronto? Manda rodar! ðŸš€
